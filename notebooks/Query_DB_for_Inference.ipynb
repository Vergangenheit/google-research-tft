{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import Engine, Connection\n",
    "from sqlalchemy import create_engine\n",
    "from os import getenv\n",
    "from typing import List, Dict, Optional\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series, Timestamp\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except:\n",
    "    print('No \".env\" file or python-dotenv not installed... Using default env variables...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_connection() -> Engine:\n",
    "    dbname: Optional[str] = getenv('POSTGRES_DB_NAME')\n",
    "    host: Optional[str] = getenv('POSTGRES_HOST')\n",
    "    user: Optional[str] = getenv('POSTGRES_USERNAME')\n",
    "    password: Optional[str] = getenv('POSTGRES_PASSWORD')\n",
    "    port: Optional[str] = getenv('POSTGRES_PORT')\n",
    "        \n",
    "    postgres_str: str = f'postgresql://{user}:{password}@{host}:{port}/{dbname}'\n",
    "    \n",
    "    engine: Engine = create_engine(postgres_str)\n",
    "    \n",
    "    return engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHAT WE HAVE TO QUERY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's start by define date intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate: str = (datetime.now(pytz.timezone('UTC')) - dt.timedelta(hours=167))\n",
    "endDate: str = datetime.now(pytz.timezone('UTC'))\n",
    "startDate, endDate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDate: datetime = endDate + dt.timedelta(hours=12)\n",
    "targetDates: List[datetime] = [endDate + dt.timedelta(hours=i) for i in range(1,13)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERT INTO STRINGS AND PUSHED TO THE START OF THE HOUR (xx:00:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start: str = startDate.strftime(\"%Y-%m-%d %H:00:00\")\n",
    "end: str = endDate.strftime(\"%Y-%m-%d %H:00:00\")\n",
    "targets: List[str] = [date.strftime(\"%Y-%m-%d %H:00:00\") for date in targetDates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUERY OBSERVED INPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where are they?\n",
    "\n",
    "table: \"meteomatics_weather\" (for start to end - 1)\n",
    "\n",
    "table: \"meteomatics_forecast_weather\" (for end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1: str = \"SELECT * FROM meteomatics_weather WHERE timestamp_utc between '{}' and '{}'\"\n",
    "observed_df1: DataFrame = pd.read_sql_query(query1.format(start, end), con=db_connection())\n",
    "observed_df1.drop(['id'], axis=1, inplace=True)\n",
    "observed_df1.rename(columns={'timestamp_utc': 'time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2: str = \"SELECT * FROM meteomatics_forecast_weather WHERE forecast_timestamp_utc = '{}' and timestamp_query_utc = '{}'\"\n",
    "observed_df2: DataFrame = pd.read_sql_query(query2.format(end, end), con=db_connection())\n",
    "observed_df2.drop(['id','timestamp_query_utc'], axis=1, inplace=True)\n",
    "observed_df2.rename(columns={'forecast_timestamp_utc': 'time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCAT THE TWO OBSERVED DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_list: List = ['UP_PRCLCDPLRM_1',\n",
    "'UP_PRCLCDMZRD_1',\n",
    "'UP_PRCLCDPRZZ_1',\n",
    "'UP_PRCLCMINEO_1',\n",
    "'UP_PEPIZZA_1',\n",
    "'UP_MPNTLCSMBC_1',\n",
    "'UP_MPNTLCDMRN_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df: DataFrame = pd.concat([observed_df1, observed_df2], axis=0, ignore_index=True)\n",
    "observed_df: DataFrame = observed_df.sort_values(by=['time','plant_code'], ascending=True, ignore_index=True)\n",
    "observed_df: DataFrame = observed_df[observed_df['plant_code'].isin(farm_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUERY KNOWN INPUTS (FORECASTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where are they?\n",
    "\n",
    "table: \"meteomatics_forecast_weather\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_fore: str = \"SELECT * FROM meteomatics_forecast_weather WHERE forecast_timestamp_utc between '{}' and '{}'\"\n",
    "# known_df: DataFrame = pd.read_sql_query(query_fore.format(targets[0], targets[-1]), con=db_connection())\n",
    "# known_df.drop(['id', 'timestamp_query_utc'], axis=1, inplace=True)\n",
    "# # known_df.drop(['id'], axis=1, inplace=True)\n",
    "# known_df: DataFrame = known_df.sort_values(by=['forecast_timestamp_utc','plant_code'], ascending=True, ignore_index=True)\n",
    "# known_df: DataFrame = known_df[known_df['plant_code'].isin(farm_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_fore: str = \"SELECT * FROM meteomatics_forecast_weather WHERE forecast_timestamp_utc between '{}' and '{}'\"\n",
    "known_df: DataFrame = pd.read_sql_query(query_fore.format(targets[0], targets[-1]), con=db_connection())\n",
    "known_df.drop(['id'], axis=1, inplace=True)\n",
    "known_df: DataFrame = known_df.sort_values(by=['forecast_timestamp_utc', 'plant_code'], ascending=True, ignore_index=True)\n",
    "known_df['diff'] = known_df['forecast_timestamp_utc'] - known_df['timestamp_query_utc']\n",
    "known_df = known_df.sort_values('diff', ascending=True).drop_duplicates(subset=['plant_code', 'forecast_timestamp_utc'], keep='first')\n",
    "# assert known_df['timestamp_query_utc'].unique() == pd.Timestamp(targets[0])\n",
    "known_df.drop(['timestamp_query_utc'], axis=1, inplace=True)\n",
    "known_df: DataFrame = known_df[known_df['plant_code'].isin(farm_list)]\n",
    "known_df.rename(columns={'forecast_timestamp_utc': 'time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST observed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maserio_ob = observed_df[observed_df['plant_code']=='UP_MPNTLCDMRN_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(maserio_ob) == 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maserio_kn = known_df[known_df['plant_code']=='UP_MPNTLCDMRN_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maserio_kn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCATENATE OBSERVED AND KNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['plant_code', 'time', 'dew_point_2m_C', 'temperature_2m_C', 'msl_pressure_hPa', 'sfc_pressure_hPa',\n",
    "           'precipitation_1h_mm', 'wind_speed_mean_10m_1h_ms',\n",
    "           'wind_speed_mean_100m_1h_ms', 'wind_dir_mean_100m_1h_d', 'wind_dir_mean_10m_1h_d', 'wind_gusts_10m_1h_ms',\n",
    "           'wind_gusts_10m_ms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df = observed_df[columns]\n",
    "known_df = known_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: DataFrame = pd.concat([observed_df, known_df], axis=0, ignore_index=True)\n",
    "df = df.sort_values(['plant_code', 'time'], ascending=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add other engineered features\n",
    "timestamp_s: Series = df['time'].map(datetime.timestamp)\n",
    "\n",
    "day: int = 24 * 60 * 60\n",
    "year: float = 365.2425 * day\n",
    "\n",
    "df['Day sin']: Series = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['Day cos']: Series = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "df['Year sin']: Series = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "df['Year cos']: Series = np.cos(timestamp_s * (2 * np.pi / year))\n",
    "    \n",
    "earliest_time: Timestamp = df.time.min()\n",
    "df['t']: Series = (df['time'] - earliest_time).dt.seconds / 60 / 60 + (df['time'] - earliest_time).dt.days * 24\n",
    "df['days_from_start']: Series = (df['time'] - earliest_time).dt.days\n",
    "df[\"id\"] = df[\"plant_code\"]\n",
    "df['hour']: Series = df[\"time\"].dt.hour\n",
    "df['day']: Series = df[\"time\"].dt.day\n",
    "df['day_of_week']: Series = df[\"time\"].dt.dayofweek\n",
    "df['month']: Series = df[\"time\"].dt.month\n",
    "df['categorical_id']: Series = df['id'].copy()\n",
    "df['hours_from_start']: Series = df['t']\n",
    "df['categorical_day_of_week']: Series = df['day_of_week'].copy()\n",
    "df['categorical_hour']: Series = df['hour'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tft",
   "language": "python",
   "name": "tft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
