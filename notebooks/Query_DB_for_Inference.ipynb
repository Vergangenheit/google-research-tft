{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import Engine, Connection\n",
    "from sqlalchemy import create_engine\n",
    "from os import getenv\n",
    "from typing import List, Dict, Optional\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series, Timestamp\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl.ETL import db_connection, group_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except:\n",
    "    print('No \".env\" file or python-dotenv not installed... Using default env variables...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_connection() -> Engine:\n",
    "    dbname: Optional[str] = getenv('POSTGRES_DB_NAME')\n",
    "    host: Optional[str] = getenv('POSTGRES_HOST')\n",
    "    user: Optional[str] = getenv('POSTGRES_USERNAME')\n",
    "    password: Optional[str] = getenv('POSTGRES_PASSWORD')\n",
    "    port: Optional[str] = getenv('POSTGRES_PORT')\n",
    "        \n",
    "    postgres_str: str = f'postgresql://{user}:{password}@{host}:{port}/{dbname}'\n",
    "    \n",
    "    engine: Engine = create_engine(postgres_str)\n",
    "    \n",
    "    return engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHAT WE HAVE TO QUERY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's start by define date intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2021, 7, 6, 6, 50, 7, 814950, tzinfo=<UTC>),\n",
       " datetime.datetime(2021, 7, 13, 5, 50, 7, 814950, tzinfo=<UTC>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startDate: str = (datetime.now(pytz.timezone('UTC')) - dt.timedelta(hours=167))\n",
    "endDate: str = datetime.now(pytz.timezone('UTC'))\n",
    "startDate, endDate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDate: datetime = endDate + dt.timedelta(hours=12)\n",
    "targetDates: List[datetime] = [endDate + dt.timedelta(hours=i) for i in range(1,13)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERT INTO STRINGS AND PUSHED TO THE START OF THE HOUR (xx:00:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start: str = startDate.strftime(\"%Y-%m-%d %H:00:00\")\n",
    "end: str = endDate.strftime(\"%Y-%m-%d %H:00:00\")\n",
    "targets: List[str] = [date.strftime(\"%Y-%m-%d %H:00:00\") for date in targetDates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2021-07-06 06:00:00', '2021-07-13 05:00:00')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-07-13 06:00:00',\n",
       " '2021-07-13 07:00:00',\n",
       " '2021-07-13 08:00:00',\n",
       " '2021-07-13 09:00:00',\n",
       " '2021-07-13 10:00:00',\n",
       " '2021-07-13 11:00:00',\n",
       " '2021-07-13 12:00:00',\n",
       " '2021-07-13 13:00:00',\n",
       " '2021-07-13 14:00:00',\n",
       " '2021-07-13 15:00:00',\n",
       " '2021-07-13 16:00:00',\n",
       " '2021-07-13 17:00:00']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUERY OBSERVED INPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where are they?\n",
    "\n",
    "table: \"meteomatics_weather\" (for start to end - 1)\n",
    "\n",
    "table: \"meteomatics_forecast_weather\" (for end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1: str = \"SELECT * FROM meteomatics_weather WHERE timestamp_utc between '{}' and '{}'\"\n",
    "observed_df1: DataFrame = pd.read_sql_query(query1.format(start, end), con=db_connection())\n",
    "observed_df1.drop(['id'], axis=1, inplace=True)\n",
    "observed_df1.rename(columns={'timestamp_utc': 'time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2: str = \"SELECT * FROM meteomatics_forecast_weather WHERE forecast_timestamp_utc = '{}' and timestamp_query_utc = '{}'\"\n",
    "observed_df2: DataFrame = pd.read_sql_query(query2.format(end, end), con=db_connection())\n",
    "observed_df2.drop(['id','timestamp_query_utc'], axis=1, inplace=True)\n",
    "observed_df2.rename(columns={'forecast_timestamp_utc': 'time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCAT THE TWO OBSERVED DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_list: List = ['UP_PRCLCDPLRM_1',\n",
    "'UP_PRCLCDMZRD_1',\n",
    "'UP_PRCLCDPRZZ_1',\n",
    "'UP_PRCLCMINEO_1',\n",
    "'UP_PEPIZZA_1',\n",
    "'UP_MPNTLCSMBC_1',\n",
    "'UP_MPNTLCDMRN_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df: DataFrame = pd.concat([observed_df1, observed_df2], axis=0, ignore_index=True)\n",
    "observed_df: DataFrame = observed_df[observed_df['plant_code'].isin(farm_list)]\n",
    "observed_df: DataFrame = observed_df.sort_values(by=['plant_code', 'time'], ascending=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUERY TARGETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where are they?\n",
    "\n",
    "table: \"sorgenia_energy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tar: str = \"SELECT * FROM sorgenia_energy WHERE start_date_utc >= '{}' and end_date_utc <= '{}'\"\n",
    "past_targets: DataFrame = pd.read_sql_query(query_tar.format(start, end), con=db_connection())\n",
    "past_targets: DataFrame = group_hourly(past_targets)\n",
    "past_targets: DataFrame = past_targets[past_targets['plant_name_up'].isin(farm_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGE KWH TO observed_df ON time and plant_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df = observed_df.merge(past_targets, how='left', left_on=['plant_code', 'time'], right_on=['plant_name_up', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df['kwh'] = observed_df['kwh'].fillna(method='ffill')\n",
    "observed_df.drop(['plant_name_up'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUERY KNOWN INPUTS (FORECASTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where are they?\n",
    "\n",
    "table: \"meteomatics_forecast_weather\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_fore: str = \"SELECT * FROM meteomatics_forecast_weather WHERE forecast_timestamp_utc between '{}' and '{}'\"\n",
    "# known_df: DataFrame = pd.read_sql_query(query_fore.format(targets[0], targets[-1]), con=db_connection())\n",
    "# known_df.drop(['id', 'timestamp_query_utc'], axis=1, inplace=True)\n",
    "# # known_df.drop(['id'], axis=1, inplace=True)\n",
    "# known_df: DataFrame = known_df.sort_values(by=['forecast_timestamp_utc','plant_code'], ascending=True, ignore_index=True)\n",
    "# known_df: DataFrame = known_df[known_df['plant_code'].isin(farm_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_fore: str = \"SELECT * FROM meteomatics_forecast_weather WHERE forecast_timestamp_utc between '{}' and '{}'\"\n",
    "known_df: DataFrame = pd.read_sql_query(query_fore.format(targets[0], targets[-1]), con=db_connection())\n",
    "known_df.drop(['id'], axis=1, inplace=True)\n",
    "known_df: DataFrame = known_df.sort_values(by=['forecast_timestamp_utc', 'plant_code'], ascending=True, ignore_index=True)\n",
    "known_df['diff'] = known_df['forecast_timestamp_utc'] - known_df['timestamp_query_utc']\n",
    "known_df = known_df.sort_values('diff', ascending=True).drop_duplicates(subset=['plant_code', 'forecast_timestamp_utc'], keep='first')\n",
    "# assert known_df['timestamp_query_utc'].unique() == pd.Timestamp(targets[0])\n",
    "known_df.drop(['timestamp_query_utc'], axis=1, inplace=True)\n",
    "known_df: DataFrame = known_df[known_df['plant_code'].isin(farm_list)]\n",
    "known_df.rename(columns={'forecast_timestamp_utc': 'time'}, inplace=True)\n",
    "known_df['kwh'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST observed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maserio_ob = observed_df[observed_df['plant_code']=='UP_MPNTLCDMRN_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(maserio_ob) == 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maserio_kn = known_df[known_df['plant_code']=='UP_MPNTLCDMRN_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maserio_kn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCATENATE OBSERVED AND KNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['plant_code', 'time', 'kwh', 'dew_point_2m_C', 'temperature_2m_C', 'msl_pressure_hPa', 'sfc_pressure_hPa',\n",
    "           'precipitation_1h_mm', 'wind_speed_mean_10m_1h_ms',\n",
    "           'wind_speed_mean_100m_1h_ms', 'wind_dir_mean_100m_1h_d', 'wind_dir_mean_10m_1h_d', 'wind_gusts_10m_1h_ms',\n",
    "           'wind_gusts_10m_ms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_df = observed_df[columns]\n",
    "known_df = known_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: DataFrame = pd.concat([observed_df, known_df], axis=0, ignore_index=True)\n",
    "df = df.sort_values(['plant_code', 'time'], ascending=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add other engineered features\n",
    "timestamp_s: Series = df['time'].map(datetime.timestamp)\n",
    "\n",
    "day: int = 24 * 60 * 60\n",
    "year: float = 365.2425 * day\n",
    "\n",
    "df['Day sin']: Series = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['Day cos']: Series = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "df['Year sin']: Series = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "df['Year cos']: Series = np.cos(timestamp_s * (2 * np.pi / year))\n",
    "    \n",
    "earliest_time: Timestamp = df.time.min()\n",
    "df['t']: Series = (df['time'] - earliest_time).dt.seconds / 60 / 60 + (df['time'] - earliest_time).dt.days * 24\n",
    "df['days_from_start']: Series = (df['time'] - earliest_time).dt.days\n",
    "df[\"id\"] = df[\"plant_code\"]\n",
    "df['hour']: Series = df[\"time\"].dt.hour\n",
    "df['day']: Series = df[\"time\"].dt.day\n",
    "df['day_of_week']: Series = df[\"time\"].dt.dayofweek\n",
    "df['month']: Series = df[\"time\"].dt.month\n",
    "df['categorical_id']: Series = df['id'].copy()\n",
    "df['hours_from_start']: Series = df['t']\n",
    "df['categorical_day_of_week']: Series = df['day_of_week'].copy()\n",
    "df['categorical_hour']: Series = df['hour'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kwh'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maserio = df[df['id']=='UP_MPNTLCDMRN_1']\n",
    "df_maserio['kwh'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tft",
   "language": "python",
   "name": "tft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
