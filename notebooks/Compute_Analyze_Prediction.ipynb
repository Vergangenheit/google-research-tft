{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to apply trained model on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series, Timestamp\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "from tensorflow.compat.v1 import Session, ConfigProto\n",
    "from tensorflow.python.eager.context import PhysicalDevice\n",
    "from typing import Dict, List, Union, Generator\n",
    "import os\n",
    "from numpy import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_formatters.base import GenericDataFormatter, InputTypes, DataTypes\n",
    "from data_formatters.erg_wind import ErgFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expt_settings.configs import ExperimentConfig\n",
    "from libs.hyperparam_opt import HyperparamOptManager\n",
    "from libs.tft_model import TemporalFusionTransformer\n",
    "import libs.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu: List[PhysicalDevice] = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting GPU ID=0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow setup\n",
    "default_keras_session: Session = tf1.keras.backend.get_session()\n",
    "tf_config: ConfigProto = utils.get_default_tensorflow_config(tf_device=\"gpu\", gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path: str = r'C:\\Users\\Lorenzo\\PycharmProjects\\TFT\\outputs\\data\\erg_wind\\data\\erg_7farms_final.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data: DataFrame = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_mw</th>\n",
       "      <th>time</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>2m_devpoint [C]</th>\n",
       "      <th>temperature [C]</th>\n",
       "      <th>mean_sealev_pressure [hPa]</th>\n",
       "      <th>surface pressure [hPa]</th>\n",
       "      <th>precipitation [m]</th>\n",
       "      <th>10_wind_speed</th>\n",
       "      <th>10_u_wind</th>\n",
       "      <th>...</th>\n",
       "      <th>days_from_start</th>\n",
       "      <th>id</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>categorical_id</th>\n",
       "      <th>hours_from_start</th>\n",
       "      <th>categorical_day_of_week</th>\n",
       "      <th>categorical_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.787686</td>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>9.024996</td>\n",
       "      <td>-0.595344</td>\n",
       "      <td>3.746035</td>\n",
       "      <td>1023.987081</td>\n",
       "      <td>952.041642</td>\n",
       "      <td>0.017248</td>\n",
       "      <td>3.077197</td>\n",
       "      <td>-0.290841</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BISACCIA2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BISACCIA2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.321628</td>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>9.115065</td>\n",
       "      <td>0.186824</td>\n",
       "      <td>4.068633</td>\n",
       "      <td>1023.939205</td>\n",
       "      <td>952.043340</td>\n",
       "      <td>0.066301</td>\n",
       "      <td>3.056552</td>\n",
       "      <td>-0.466334</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BISACCIA2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BISACCIA2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.217240</td>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>8.807608</td>\n",
       "      <td>0.119856</td>\n",
       "      <td>3.750193</td>\n",
       "      <td>1023.588209</td>\n",
       "      <td>951.729260</td>\n",
       "      <td>0.053635</td>\n",
       "      <td>3.240812</td>\n",
       "      <td>-0.547045</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BISACCIA2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BISACCIA2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.117007</td>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>9.551801</td>\n",
       "      <td>-0.312831</td>\n",
       "      <td>3.430814</td>\n",
       "      <td>1023.465573</td>\n",
       "      <td>951.629732</td>\n",
       "      <td>0.026092</td>\n",
       "      <td>3.616165</td>\n",
       "      <td>-0.753333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BISACCIA2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BISACCIA2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.415503</td>\n",
       "      <td>2019-01-01 05:00:00</td>\n",
       "      <td>8.734134</td>\n",
       "      <td>-0.526966</td>\n",
       "      <td>3.453347</td>\n",
       "      <td>1023.853208</td>\n",
       "      <td>951.984117</td>\n",
       "      <td>0.016079</td>\n",
       "      <td>3.446475</td>\n",
       "      <td>-0.759338</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BISACCIA2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BISACCIA2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   energy_mw                 time  Wind Speed  2m_devpoint [C]  \\\n",
       "0  11.787686  2019-01-01 01:00:00    9.024996        -0.595344   \n",
       "1  12.321628  2019-01-01 02:00:00    9.115065         0.186824   \n",
       "2  12.217240  2019-01-01 03:00:00    8.807608         0.119856   \n",
       "3  12.117007  2019-01-01 04:00:00    9.551801        -0.312831   \n",
       "4  12.415503  2019-01-01 05:00:00    8.734134        -0.526966   \n",
       "\n",
       "   temperature [C]  mean_sealev_pressure [hPa]  surface pressure [hPa]  \\\n",
       "0         3.746035                 1023.987081              952.041642   \n",
       "1         4.068633                 1023.939205              952.043340   \n",
       "2         3.750193                 1023.588209              951.729260   \n",
       "3         3.430814                 1023.465573              951.629732   \n",
       "4         3.453347                 1023.853208              951.984117   \n",
       "\n",
       "   precipitation [m]  10_wind_speed  10_u_wind  ...  days_from_start  \\\n",
       "0           0.017248       3.077197  -0.290841  ...                0   \n",
       "1           0.066301       3.056552  -0.466334  ...                0   \n",
       "2           0.053635       3.240812  -0.547045  ...                0   \n",
       "3           0.026092       3.616165  -0.753333  ...                0   \n",
       "4           0.016079       3.446475  -0.759338  ...                0   \n",
       "\n",
       "          id  hour  day  day_of_week  month categorical_id  hours_from_start  \\\n",
       "0  BISACCIA2     1    1            1      1      BISACCIA2               0.0   \n",
       "1  BISACCIA2     2    1            1      1      BISACCIA2               1.0   \n",
       "2  BISACCIA2     3    1            1      1      BISACCIA2               2.0   \n",
       "3  BISACCIA2     4    1            1      1      BISACCIA2               3.0   \n",
       "4  BISACCIA2     5    1            1      1      BISACCIA2               4.0   \n",
       "\n",
       "   categorical_day_of_week categorical_hour  \n",
       "0                        1                1  \n",
       "1                        1                2  \n",
       "2                        1                3  \n",
       "3                        1                4  \n",
       "4                        1                5  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['time'] = raw_data['time'].astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ExperimentConfig('erg_wind', r'C:\\Users\\Lorenzo\\PycharmProjects\\TFT\\outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter: ErgFormatter = config.make_data_formatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_path: str = config.data_csv_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting scalers with training data...\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = formatter.split_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_definitions = formatter.get_column_definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', <DataTypes.REAL_VALUED: 0>, <InputTypes.ID: 4>),\n",
       " ('time', <DataTypes.DATE: 2>, <InputTypes.TIME: 5>),\n",
       " ('energy_mw', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>),\n",
       " ('hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>),\n",
       " ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>),\n",
       " ('hours_from_start', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>),\n",
       " ('Wind Speed', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('2m_devpoint [C]',\n",
       "  <DataTypes.REAL_VALUED: 0>,\n",
       "  <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('temperature [C]',\n",
       "  <DataTypes.REAL_VALUED: 0>,\n",
       "  <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('mean_sealev_pressure [hPa]',\n",
       "  <DataTypes.REAL_VALUED: 0>,\n",
       "  <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('surface pressure [hPa]',\n",
       "  <DataTypes.REAL_VALUED: 0>,\n",
       "  <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('precipitation [m]',\n",
       "  <DataTypes.REAL_VALUED: 0>,\n",
       "  <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('10_wind_speed', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('10_u_wind', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('10_v_wind', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('instant_wind_gust [m/s]',\n",
       "  <DataTypes.REAL_VALUED: 0>,\n",
       "  <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('Day sin', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('Day cos', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('Year sin', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('Year cos', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>),\n",
       " ('categorical_id', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, valid_samples = formatter.get_num_samples_for_calibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up default params\n",
    "fixed_params: Dict = formatter.get_experiment_params()\n",
    "params: Dict = formatter.get_default_model_params()\n",
    "params[\"model_folder\"]: str = os.path.join(config.model_folder, \"fixed\")\n",
    "model_folder = os.path.join(config.model_folder, \"fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up hyperparam manager\n",
    "print(\"*** Loading hyperparm manager ***\")\n",
    "opt_manager = HyperparamOptManager({k: [params[k]] for k in params},\n",
    "                                   fixed_params, model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder: str = opt_manager.hyperparam_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE'RE EXPECTING THE MODEL TO BE FED INPUTS WHICH ARE STARTING FROM THE FOLLOWING TIMESTAMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[168:178, [0,1,25]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*** Running tests ***\")\n",
    "tf1.reset_default_graph()\n",
    "with tf.Graph().as_default(), tf1.Session(config=tf_config) as sess:\n",
    "    tf1.keras.backend.set_session(sess)\n",
    "    params: Dict = opt_manager.get_next_parameters()\n",
    "    params['exp_name'] = 'erg_wind'\n",
    "    params['data_folder'] = os.path.abspath(os.path.join(data_csv_path, os.pardir))\n",
    "    model = TemporalFusionTransformer(params, use_cudnn=False)\n",
    "    params.pop('exp_name', None)\n",
    "    params.pop('data_folder', None)\n",
    "    # load model\n",
    "    model.load(opt_manager.hyperparam_folder, use_keras_loadings=True)\n",
    "    \n",
    "#     print(\"Computing best validation loss\")\n",
    "#     val_loss: Series = model.evaluate(valid)\n",
    "        \n",
    "    print(\"Computing test loss\")\n",
    "    output_map: Dict = model.predict(test, return_targets=True)\n",
    "    print(f\"Output map returned a dict with keys {output_map.get('p50').shape}\")\n",
    "    targets: DataFrame = formatter.format_predictions(output_map[\"targets\"])\n",
    "    p50_forecast: DataFrame = formatter.format_predictions(output_map[\"p50\"])\n",
    "    p90_forecast: DataFrame = formatter.format_predictions(output_map[\"p90\"])\n",
    "        \n",
    "    # save all\n",
    "    print(\"saving predictions and targets\")\n",
    "    targets.to_csv(os.path.join(opt_manager.hyperparam_folder, \"targets.csv\"), index=False)\n",
    "    p50_forecast.to_csv(os.path.join(opt_manager.hyperparam_folder, \"p50.csv\"), index=False)\n",
    "    p90_forecast.to_csv(os.path.join(opt_manager.hyperparam_folder, \"p90.csv\"), index=False)\n",
    "        \n",
    "    def extract_numerical_data(data: DataFrame) -> DataFrame:\n",
    "        \"\"\"Strips out forecast time and identifier columns.\"\"\"\n",
    "        return data[[\n",
    "            col for col in data.columns\n",
    "            if col not in {\"forecast_time\", \"identifier\"}\n",
    "        ]]\n",
    "    \n",
    "    p50_loss = utils.numpy_normalised_quantile_loss(\n",
    "            extract_numerical_data(targets), extract_numerical_data(p50_forecast),\n",
    "            0.5)\n",
    "    p90_loss = utils.numpy_normalised_quantile_loss(\n",
    "        extract_numerical_data(targets), extract_numerical_data(p90_forecast),\n",
    "        0.9)\n",
    "\n",
    "    tf1.keras.backend.set_session(default_keras_session)\n",
    "\n",
    "print()\n",
    "print(\"Normalised Quantile Loss for Test Data: P50={}, P90={}\".format(\n",
    "    p50_loss.mean(), p90_loss.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.iloc[192:202, [0,20,21,24,23,2,3,4,5,6,7,8,9,10,11,12,13,14,15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNDERSTANDING SAVED PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START BY CONVERTING THE FORECAST TIME INTO PROPER DATETIME FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p50_forecast: DataFrame = pd.read_csv(os.path.join(opt_manager.hyperparam_folder, \"p50.csv\"))\n",
    "p90_forecast: DataFrame = pd.read_csv(os.path.join(opt_manager.hyperparam_folder, \"p90.csv\"))\n",
    "targets: DataFrame = pd.read_csv(os.path.join(opt_manager.hyperparam_folder, \"targets.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p90_forecast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE CAN'T FETCH DATES BECAUSE WE CONFIGURED THE TIME INDEX WITH THE \"hours_from_start\" WHICH GOT SCALED DURING PRE-TRAINING.\n",
    "WE SHOULD RETRY USING THE DATETIME FORMATTED COLUMN AS TIME INDEX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tft",
   "language": "python",
   "name": "tft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
