{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERG DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to apply trained model on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series, Timestamp\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "from tensorflow.compat.v1 import Session, ConfigProto\n",
    "from tensorflow.python.eager.context import PhysicalDevice\n",
    "from typing import Dict, List, Union, Generator\n",
    "import os\n",
    "from numpy import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_formatters.base import GenericDataFormatter, InputTypes, DataTypes\n",
    "from data_formatters.erg_wind import ErgFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expt_settings.configs import ExperimentConfig\n",
    "from libs.hyperparam_opt import HyperparamOptManager\n",
    "from libs.tft_model import TemporalFusionTransformer\n",
    "import libs.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu: List[PhysicalDevice] = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow setup\n",
    "default_keras_session: Session = tf1.keras.backend.get_session()\n",
    "tf_config: ConfigProto = utils.get_default_tensorflow_config(tf_device=\"gpu\", gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path: str = r'C:\\Users\\Lorenzo\\PycharmProjects\\TFT\\outputs\\data\\erg_wind\\data\\erg_7farms_final.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data: DataFrame = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['time'] = raw_data['time'].astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ExperimentConfig('erg_wind', r'C:\\Users\\Lorenzo\\PycharmProjects\\TFT\\outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter: ErgFormatter = config.make_data_formatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_path: str = config.data_csv_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = formatter.split_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_definitions = formatter.get_column_definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, valid_samples = formatter.get_num_samples_for_calibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up default params\n",
    "fixed_params: Dict = formatter.get_experiment_params()\n",
    "params: Dict = formatter.get_default_model_params()\n",
    "params[\"model_folder\"]: str = os.path.join(config.model_folder, \"fixed\")\n",
    "model_folder = os.path.join(config.model_folder, \"fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up hyperparam manager\n",
    "print(\"*** Loading hyperparm manager ***\")\n",
    "opt_manager = HyperparamOptManager({k: [params[k]] for k in params},\n",
    "                                   fixed_params, model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder: str = opt_manager.hyperparam_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE'RE EXPECTING THE MODEL TO BE FED INPUTS WHICH ARE STARTING FROM THE FOLLOWING TIMESTAMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[168:178, [0,1,25]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*** Running tests ***\")\n",
    "tf1.reset_default_graph()\n",
    "with tf.Graph().as_default(), tf1.Session(config=tf_config) as sess:\n",
    "    tf1.keras.backend.set_session(sess)\n",
    "    params: Dict = opt_manager.get_next_parameters()\n",
    "    params['exp_name'] = 'erg_wind'\n",
    "    params['data_folder'] = os.path.abspath(os.path.join(data_csv_path, os.pardir))\n",
    "    model = TemporalFusionTransformer(params, use_cudnn=False)\n",
    "    params.pop('exp_name', None)\n",
    "    params.pop('data_folder', None)\n",
    "    # load model\n",
    "    model.load(opt_manager.hyperparam_folder, use_keras_loadings=True)\n",
    "    \n",
    "#     print(\"Computing best validation loss\")\n",
    "#     val_loss: Series = model.evaluate(valid)\n",
    "        \n",
    "    print(\"Computing test loss\")\n",
    "    output_map: Dict = model.predict(test, return_targets=True)\n",
    "    print(f\"Output map returned a dict with keys {output_map.get('p50').shape}\")\n",
    "    targets: DataFrame = formatter.format_predictions(output_map[\"targets\"])\n",
    "    p50_forecast: DataFrame = formatter.format_predictions(output_map[\"p50\"])\n",
    "    p90_forecast: DataFrame = formatter.format_predictions(output_map[\"p90\"])\n",
    "        \n",
    "    # save all\n",
    "    print(\"saving predictions and targets\")\n",
    "    targets.to_csv(os.path.join(opt_manager.hyperparam_folder, \"targets.csv\"), index=False)\n",
    "    p50_forecast.to_csv(os.path.join(opt_manager.hyperparam_folder, \"p50.csv\"), index=False)\n",
    "    p90_forecast.to_csv(os.path.join(opt_manager.hyperparam_folder, \"p90.csv\"), index=False)\n",
    "        \n",
    "    def extract_numerical_data(data: DataFrame) -> DataFrame:\n",
    "        \"\"\"Strips out forecast time and identifier columns.\"\"\"\n",
    "        return data[[\n",
    "            col for col in data.columns\n",
    "            if col not in {\"forecast_time\", \"identifier\"}\n",
    "        ]]\n",
    "    \n",
    "    p50_loss = utils.numpy_normalised_quantile_loss(\n",
    "            extract_numerical_data(targets), extract_numerical_data(p50_forecast),\n",
    "            0.5)\n",
    "    p90_loss = utils.numpy_normalised_quantile_loss(\n",
    "        extract_numerical_data(targets), extract_numerical_data(p90_forecast),\n",
    "        0.9)\n",
    "\n",
    "    tf1.keras.backend.set_session(default_keras_session)\n",
    "\n",
    "print()\n",
    "print(\"Normalised Quantile Loss for Test Data: P50={}, P90={}\".format(\n",
    "    p50_loss.mean(), p90_loss.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.iloc[192:202, [0,20,21,24,23,2,3,4,5,6,7,8,9,10,11,12,13,14,15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNDERSTANDING SAVED PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START BY CONVERTING THE FORECAST TIME INTO PROPER DATETIME FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p50_forecast: DataFrame = pd.read_csv(os.path.join(opt_manager.hyperparam_folder, \"p50.csv\"))\n",
    "p90_forecast: DataFrame = pd.read_csv(os.path.join(opt_manager.hyperparam_folder, \"p90.csv\"))\n",
    "targets: DataFrame = pd.read_csv(os.path.join(opt_manager.hyperparam_folder, \"targets.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p90_forecast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE CAN'T FETCH DATES BECAUSE WE CONFIGURED THE TIME INDEX WITH THE \"hours_from_start\" WHICH GOT SCALED DURING PRE-TRAINING.\n",
    "WE SHOULD RETRY USING THE DATETIME FORMATTED COLUMN AS TIME INDEX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tft",
   "language": "python",
   "name": "tft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
