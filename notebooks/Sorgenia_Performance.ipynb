{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_formatters.base import GenericDataFormatter, InputTypes, DataTypes\n",
    "from data_formatters.sorgenia_wind import SorgeniaFormatter\n",
    "from expt_settings.configs import ExperimentConfig\n",
    "from libs.hyperparam_opt import HyperparamOptManager\n",
    "from libs.tft_model import TemporalFusionTransformer\n",
    "import libs.utils as utils\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series, Timestamp, Index\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1\n",
    "from tensorflow.compat.v1 import Session, ConfigProto\n",
    "from tensorflow.python.eager.context import PhysicalDevice\n",
    "from typing import Dict, List, Union, Generator\n",
    "from numpy import load\n",
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objects import Figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT FUNCTIONS TO TRANSFORM DF AND CALCULATE MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import mape\n",
    "from inference import utils as infutils\n",
    "from script_download_data import preprocess_sorgenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu: List[PhysicalDevice] = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting GPU ID=0\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow setup\n",
    "default_keras_session: Session = tf1.keras.backend.get_session()\n",
    "tf_config: ConfigProto = utils.get_default_tensorflow_config(tf_device=\"gpu\", gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path: str = r'C:\\Users\\Lorenzo\\PycharmProjects\\TFT\\outputs\\data\\sorgenia_wind\\data\\sorgenia_wind\\data\\sorgenia_final_cop.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ExperimentConfig('sorgenia_wind', r'C:\\Users\\Lorenzo\\PycharmProjects\\TFT\\outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data into DataFrame\n",
    "# raw_data: DataFrame = pd.read_csv(file_path)\n",
    "raw_data: DataFrame = preprocess_sorgenia('copernicus', config, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START WITH MODEL1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wind Forecasts as known input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter: SorgeniaFormatter = config.make_data_formatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_path: str = config.data_csv_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = formatter.split_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up default params\n",
    "fixed_params: Dict = formatter.get_experiment_params()\n",
    "params: Dict = formatter.get_default_model_params()\n",
    "params[\"model_folder\"]: str = os.path.join(config.model_folder, \"fixed\")\n",
    "model_folder = os.path.join(config.model_folder, \"fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up hyperparam manager\n",
    "print(\"*** Loading hyperparm manager ***\")\n",
    "opt_manager = HyperparamOptManager({k: [params[k]] for k in params},\n",
    "                                   fixed_params, model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_path: str = r'C:\\Users\\Lorenzo\\savedmodels_sorgenia_wind_known'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictions(test: DataFrame, opt_manager: HyperparamOptManager, formatter: SorgeniaFormatter, tf_config: ConfigProto):\n",
    "    print(\"*** Running tests ***\")\n",
    "    tf1.reset_default_graph()\n",
    "    with tf.Graph().as_default(), tf1.Session(config=tf_config) as sess:\n",
    "        tf1.keras.backend.set_session(sess)\n",
    "        params: Dict = opt_manager.get_next_parameters()\n",
    "        params['exp_name'] = 'sorgenia_wind'\n",
    "        params['data_folder'] = os.path.abspath(os.path.join(data_csv_path, os.pardir))\n",
    "        model = TemporalFusionTransformer(params, use_cudnn=False)\n",
    "        params.pop('exp_name', None)\n",
    "        params.pop('data_folder', None)\n",
    "        # load model\n",
    "        model.load(opt_manager.hyperparam_folder, use_keras_loadings=True)\n",
    "\n",
    "    #     print(\"Computing best validation loss\")\n",
    "    #     val_loss: Series = model.evaluate(valid)\n",
    "\n",
    "        print(\"Computing test loss\")\n",
    "        output_map: Dict = model.predict(test, return_targets=True)\n",
    "        print(f\"Output map returned a dict with keys {output_map.get('p50').shape}\")\n",
    "        targets: DataFrame = formatter.format_predictions(output_map[\"targets\"])\n",
    "        p50_forecast: DataFrame = formatter.format_predictions(output_map[\"p50\"])\n",
    "        p90_forecast: DataFrame = formatter.format_predictions(output_map[\"p90\"])\n",
    "\n",
    "        # save all\n",
    "        print(\"saving predictions and targets\")\n",
    "        targets.to_csv(os.path.join(opt_manager.hyperparam_folder, \"targets.csv\"), index=False)\n",
    "        p50_forecast.to_csv(os.path.join(opt_manager.hyperparam_folder, \"p50.csv\"), index=False)\n",
    "        p90_forecast.to_csv(os.path.join(opt_manager.hyperparam_folder, \"p90.csv\"), index=False)\n",
    "\n",
    "        def extract_numerical_data(data: DataFrame) -> DataFrame:\n",
    "            \"\"\"Strips out forecast time and identifier columns.\"\"\"\n",
    "            return data[[\n",
    "                col for col in data.columns\n",
    "                if col not in {\"forecast_time\", \"identifier\"}\n",
    "            ]]\n",
    "\n",
    "        p50_loss = utils.numpy_normalised_quantile_loss(\n",
    "                extract_numerical_data(targets), extract_numerical_data(p50_forecast),\n",
    "                0.5)\n",
    "        p90_loss = utils.numpy_normalised_quantile_loss(\n",
    "            extract_numerical_data(targets), extract_numerical_data(p90_forecast),\n",
    "            0.9)\n",
    "\n",
    "        tf1.keras.backend.set_session(default_keras_session)\n",
    "\n",
    "    print()\n",
    "    print(\"Normalised Quantile Loss for Test Data: P50={}, P90={}\".format(\n",
    "        p50_loss.mean(), p90_loss.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_predictions(test, opt_manager, formatter, tf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN PREDICTIONS AND TARGETS FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mape = evaluate.evaluate(opt_manager.hyperparam_folder, 'copernicus_forecasts_model', 700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT MAPE BOXPLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig: Figure = evaluate.boxplotter(df_mape)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tft",
   "language": "python",
   "name": "tft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
